



# Transformer

Transformer 由 Google Brain 团队于2017年在论文 Attention is all you need 中提出，其将自注意力作为网络结构中的一层，采用Seq2Seq模型中的encoder-decoder框架，仅仅使用自注意力和前馈网络来进行编码和解码。