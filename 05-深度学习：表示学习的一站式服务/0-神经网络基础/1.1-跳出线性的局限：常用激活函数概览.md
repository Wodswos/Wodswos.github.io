

# 从二分到Sigmoid

二分类问题通常会用到如下函数
$$
\sigma (x) = 
\begin{cases}
1 \quad \mathrm{if\ } x>0 \\
0 \quad \mathrm{otherwise}
\end{cases}
$$
但这样的函数很“生硬”，于是 sigmoid 激活函数应运而生。
$$
\mathrm{sigmoid} (x) = \frac 1 {1+e^{-x}}
$$
将输入投影到区间 $(0,1)$ 上

![](C:/Users/Five/Desktop/note/img/sigmoid.jpg)



## Tanh

$$
\tanh (x) = \frac {1-e^{-2x}} {1 + e^{-2x}}
$$



# ReLU

Rectified Linear Unit

$$
\mathrm {ReLU} (x) = \max (x,0)
$$




相比于其他的激活函数，ReLU有一个很显著的特征——运算贼快。



# 世界是连续的，测量是离散的：回归方法 + Softmax = 分类模型

| 回归                                                         | 分类                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单连续数值输出                                               | 通常为多个输出                                               |
| 自然区间 $\mathbb R$                                         | 输出 i 是预测为第 i 类的置信度                               |
| 损失函数用作衡量与真实值的差距                               |                                                              |
| ![image-20220307165556729](C:\Users\Five\Desktop\note\img\image-20220307165556729.png) | ![image-20220307165619226](C:\Users\Five\Desktop\note\img\image-20220307165619226.png) |



## Softmax：适用于衡量概率的激活函数

```python
import numpy as np
a = np.array([1,2,3,4,5])
a_max = np.max(a)
```

称上述代码中的 `a_max` 为 hardmax。
$$
\mathrm{softmax} (y_i) = \frac {e^{y_i}} {\sum _{i=1} ^{n} e^{y_i}}
$$

> 指数的好处在于不管 $y_i$ 在区间 $\mathbb R$  上的哪里，都能通过这步运算让他变成非负。（当然这只是指数的优点之一）
>
> 而非负、和为1，正是概率的基本要求。





## 交叉熵：适用于Softmax的损失函数

交叉熵常用来衡量两个概率的区别
$$
H(\mathbf  p,\mathbf q) =  - \sum _i p_i \log (q_i) \\
l (\mathbf y, \mathbf {\hat y}) = -\sum _i y_i \log(\hat y _i) 
$$

> 因为 $\mathbf y_i$ 仅有一项为1，其余均为零，损失函数可以简写为 $-\log (\hat y _y)$

> 交叉熵作为损失函数和 softmax 作为输出层的激活函数经常成对出现。



## one-hot encoding：表示分类数据的简单方法

https://www.cnblogs.com/shuaishuaidefeizhu/p/11269257.html

one-hot编码要求每个类别之间相互独立，如果之间存在某种连续型的关系，或许使用distributed respresentation（分布式）更加合适。





简言之，将每个元素（或类别、或索引）映射为相互不同的单位向量：

1. 假设有N个元素，分别标号（索引）为 0 到 N-1。
2. 为每个元素（或类别、或索引）创建⼀个⻓度为 $N$ 的零向量
3. 如果元素的索引是整数 $i$ ，则将其对应零向量的第 $i$ 处的元素设置为1（单位向量）。



