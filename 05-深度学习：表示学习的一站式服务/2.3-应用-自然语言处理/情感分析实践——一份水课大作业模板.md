<h1 style="text-align: center"> 情感分析实践 </h1>
<div style="text-align: center"><small>吴泽华</small></div>



# 摘要

回顾了基本的NLP中常用的分类方法——LSTM，简单介绍NLP领域的情感分析和现有的开源框架模型，并在开源模型的基础上进行实践和应用。



# 关键词

情感分析，LAC，分类，Paddle

# 分类方法和神经网络

2006年，Hinton提出了在非监督数据上建立多层神经网络的一个有效方法，具体分为两步：首先逐层构建单层神经元，这样每次都是训练一个单层网络；当所有层训练完后，使用wake-sleep算法进行调优。

自此，神经网络的风头一时无两。

LSTM（或者说RNN）具有“记忆”特点，使得其在自然语言处理领域大放异彩。

## LSTM

Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition, speech recognition and anomaly detection in network traffic or IDSs (intrusion detection systems).

A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.

LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications.



# 预处理

![人间真实](C:\Users\Five\Desktop\note\img\image-20201124202207311.png)

## 数据清洗

由于海量数据来源是广泛的，数据类型也是多而繁杂的，因此数据中会夹杂着不完整、重复以及错误的数据，如果直接使用这些原始数据，会严重影响数据决策的准确性和效率。

> 所谓AI，预期Python，落地SQL。

* 独立性“脏”数据，可通过记录或本身属性检验出是否包含“脏”数据
* 依赖性“脏”数据，需要综合考虑与其他记录之间的关联，很难有通用高效的处理方法。

```flow
st=>start: 原始数据
op1=>operation: 数据分析、定义清洗策略和规则
op2=>operation: 搜寻、确定、纠正错误实例
e=>end: 数据回流，得到目标数据
st->op1->op2->e
```



具体到文本处理而言，很多信息来源于网络，如果是HTML文档，需要对其去标签、图片、超链接，提取核心、通顺的文本信息。



## 中文词法分析-LAC

词法分析任务的输入是一个字符串（我们后面使用『句子』来指代它），而输出是句子中的词边界和词性、实体类别。

可通过AI开放平台-词法分析[^1] 线上体验百度的词法分析服务。

词法分析任务在自然语言处理生态链的上游，其输出为很多下游的应用如文本情感分析提供输入。



# 文本情感分析

文本情感分析(Sentiment Analysis)是指利用自然语言处理和文本挖掘技术，对带有情感色彩的主观性文本进行分析、处理和抽取的过程。

目前，文本情感分析研究涵盖了包括自然语言处理、文本挖掘、信息检索、信息抽取、机器学习和本体学等多个领域，得到了许多学者以及研究机构的关注，近几年持续成为自然语言处理和文本挖掘领域研究的热点问题之一。

情感分析任务按其分析的粒度可以分为篇章级，句子级，词或短语级；按其处理文本的类别可分为基于产品评论的情感分析和基于新闻评论的情感分析;按其研究的任务类型，可分为情感分类，情感检索和情感抽取等子问题。



## 情感分类

情感分类又称情感倾向性分析，是指对给定的文本，识别其中主观性文本的倾向是肯定还是否定的，或者说是正面还是负面的，是情感分析领域研究最多的。

通常网络文本存在大量的主观性文本和客观性文本。客观性文本是对事物的客观性描述，不带有感情色彩和情感倾向，主观性文本则是作者对各种事物的看法或想法，带有作者的喜好厌恶等情感倾向。

情感分类的对象是带有情感倾向的主观性文本，因此情感分类首先要进行文本的主客观分类。文本的主客观分类主要以情感词识别为主，利用不同的文本特征表示方法和分类器进行识别分类，对网络文本事先进行主客观分类，能够提高情感分类的速度和准确度。

### 基于语义的情感词典方法

* **构建词典**

可将词归为 4 类:通用情感词、程度副词、否定词、领域词

* **构建倾向性计算算法**

基于语义的情感词典的倾向性计算不同于所需大量训练数据集的机器学习算法，主要采用权值算法代替传统人工判别或仅利用简单统计的方法进行情感分类。
$$
\overline E = \frac{\sum^{N_p}_{i=1}wp_i+\sum_{j=1}^{N_n}wp_j} {N_p+N_n}
$$


* **确定阈值来判断文本倾向性**

一般情况下，加权计算结果为正是正面倾向，结果为负是负面倾向 ,得分为零无倾向。

经常使用的正确率、召回率和 F 值来评判算法效果。



### 基于机器学习的方法

传统基于主题的文本分类是把文本分类到各个预定义的主题上，如军事，互联网，政治，体育等，而情感分类不是基于内容本身的，而是按照文本持有的情感、态度进行判断。

现有任何机器学习的分类方法都可以用到情感分类中来。基于机器学习的情感分类，其大致流程如下：

1. 首先人工标注文本倾向性作为训练集
2. 提取文本情感特征
3. 通过机器学习的方法构造/训练分类器
4. 测试验证分类效果

常用的情感分类特征包括情感词，词性，句法结构，否定表达模板，连接，语义话题等，研究者通过挖掘各种不同的特征以期望提高情感分类的性能。

常用的特征提取方法有信息增益( Information Gain)、CHI 统计量( Chi-square) 和文档频率( Document Frequency) 等。

常用的分类方法有中心向量分类方法、KNN、朴素贝叶斯、支持向量机、条件随机场、最大熵分类器等。



## 情感检索

情感检索是从海量文本中查询到观点信息，根据主题相关度和观点倾向性对结果排序。情感检索返回的结果要同时满足主题相关和带有情感倾向或指定的情感倾向，是比情感分类更为复杂的任务。

随着人们网络检索需求的增高，在传统搜索中加入情感倾向成了搜索技术中一个新的研究热点。和传统的互联网搜索相似，情感检索有两个主要任务

* 检索和查询相关的文档或句子。
* 对检索的相关文档或句子进行排序。

与传统搜索不同的是互联网搜索的任务只要求找到和查询相关的文档和句子，而情感检索还要确定文档和句子是否表达了观点，以及观点是正面的或是负面的。

目前情感检索主要实现方法有两种：

* 按传统信息检索模型进行主题相关的文档检索，对检索结果进行情感分类
* 同时计算主题相关值和情感倾向值进行检索。

实际中主题相关和情感匹配是有关联的，需要同时计算主题相关和情感匹配，这是因为不同的情感词在文档中对不同的查询词下可能有相反的情感倾向。很多学者对排序策略进行了研究，一般是分别计算情感倾向值和查询相关度值，然后加权求和进行排序。

情感信息检索是传统信息检索技术和情感分析技术的融合，如何更好的融合二者得到理想的情感检索结果是未来要重点关注的。

> 在前段时间举办的「Search On」活动中，谷歌宣布，BERT 现在几乎为谷歌搜索引擎上的每一个基于英文的查询提供支持。而在去年，这一比例仅为 10%。

## 情感抽取

情感抽取是指抽取情感文本中有价值的情感信息，其要判断一个单词或词组在情感表达中扮演的角色，包括情感表达者识别，评价对象识别，情感观点词识别等任务。

情感抽取是情感分析的基础任务，通过对大量的情感文本分析，有价值的情感信息抽取对于情感分析的上层任务情感检索和情感分类有直接帮助，如何准确抽取情感信息一直都是研究者关注的重点。

# 开源实现

## 中文词法分析

#### THULAC

THULAC（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。THULAC具有如下几个特点：

* 能力强。利用我们集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，模型标注能力强大。
* 准确率高。该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。
* 速度较快。同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。

#### Stanford CoreNLP

Stanford CoreNLP[^2]是斯坦福大学自然语言处理小组开发的自然语言分析工具集，包含分句，分词，词性标注，命名实体识别，句法分析，指代消解，情感分析等功能，这些工具采用流式(pipeline)集成方式，各功能模块之间相互解耦，提供单独的包下载，高度灵活且可扩展性强。Stanford CoreNLP支持英文、中文、法文、德文以及西班牙文等。

Stanford CoreNLP工具采用Java语言开发，支持Java 8+。提供jar包下载，便于集成到Java代码中，同时也支持C#，Node.js，PHP，Python等语言调用。

Stanford CoreNLP的分词和命名实体识别工具是基于条件随机场模型实现的，而词性标注则是基于双向依存网络模型。

> CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 6 languages: Arabic, Chinese, English, French, German, and Spanish.

#### Paddle LAC

百度自然语言处理部研发的一款联合的词法分析工具，实现中文分词、词性标注、专名识别等功能。该工具具有以下特点与优势

- **可定制**：实现简单可控的干预机制，精准匹配用户词典对模型进行干预。词典支持长片段形式，使得干预更为精准。
- **调用便捷**：**支持一键安装**，同时提供了Python、Java和C++调用接口与调用示例，实现快速调用和集成。
- **支持移动端**: 定制超轻量级模型，体积仅为2M，主流千元手机单线程性能达200QPS，满足大多数移动端应用的需求。

代码开源在Github[^3]上。

```bash
# baseline model
sh run.sh infer
```

## 情感分类

此处仅基于百度情感倾向分析的开源代码[^4]进行展开。

情感倾向分析（Sentiment Classification，简称Senta）针对带有主观描述的中文文本，可自动判断该文本的情感极性类别并给出相应的置信度。情感类型分为积极、消极。情感倾向分析能够帮助企业理解用户消费习惯、分析热点话题和危机舆情监控，为企业提供有利的决策支持。

情感是人类的一种高级智能行为，为了识别文本的情感倾向，需要深入的语义建模。另外，不同领域（如餐饮、体育）在情感的表达各不相同，因而需要有大规模覆盖各个领域的数据进行模型训练。为此，我们通过基于深度学习的语义模型和大规模数据挖掘解决上述两个问题。

效果上，基于开源情感倾向分类数据集ChnSentiCorp进行评测，百度还开源了基于海量数据训练好的模型，该模型在ChnSentiCorp数据集上fine-tune之后（基于开源模型进行Finetune的方法请见下面章节），可以得到更好的效果。具体数据如下所示：

| 模型          | dev   | test  | 模型（finetune） | dev   | test  |
| ------------- | ----- | ----- | ---------------- | ----- | ----- |
| BOW           | 89.8% | 90.0% | BOW              | 91.3% | 90.6% |
| CNN           | 90.6% | 89.9% | CNN              | 92.4% | 91.8% |
| LSTM          | 90.0% | 91.0% | LSTM             | 93.3% | 92.2% |
| GRU           | 90.0% | 89.8% | GRU              | 93.3% | 93.2% |
| BI-LSTM       | 88.5% | 88.3% | BI-LSTM          | 92.8% | 91.4% |
| ERNIE         | 95.1% | 95.4% | ERNIE            | 95.4% | 95.5% |
| ERNIE+BI-LSTM | 95.3% | 95.2% | ERNIE+BI-LSTM    | 95.7% | 95.6% |

```bash
# 当然需要先有git工具
git clone https://github.com/PaddlePaddle/models.git
cd models/PaddleNLP/sentiment_classification

# 如果没有自定义的数据，可以用公开数据集
wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-dataset-1.0.0.tar.gz
tar -zxvf sentiment_classification-dataset-1.0.0.tar.gz

# 训练
sh run.sh train
# 预测
sh run.sh infer
```



# 应用示例

![image-20201125171416143](C:\Users\Five\Desktop\note\img\image-20201125171416143.png)

这是另一门课程的作业，一个日记APP。APP设计的初衷有如下几条

* 随时随地能够记录
* 多平台高度便捷的文件同步功能
* 提供一定的分享、协作、交流能力



通过情感分类、情感抽取等主要核心技术，再综合其他AI或数据分析技术，如阅读理解、文本相似度计算、文本分类等，可以一定程度上洞察日记APP用户的心情。

在此基础上，可以有各种进一步对软件的优化，如

* 将用户的分享推荐给更多有相同分类情感的用户
* 如果用户情绪低落，可给TA推荐更多积极的内容

> 本来打算将APP付诸实践，后来发现已经有了语雀这样的应用，各方面被完爆，遂放弃





[^1]: http://ai.baidu.com/tech/nlp/lexical
[^2]: https://stanfordnlp.github.io/CoreNLP/index.html
[^3]: https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleNLP/lexical_analysis
[^4]: https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleNLP/sentiment_classification
