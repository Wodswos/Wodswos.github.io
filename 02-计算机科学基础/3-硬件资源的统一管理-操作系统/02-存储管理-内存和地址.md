

1. ALU发出带逻辑地址的请求
2. MMU（Memory Manage Unit）从映射表查找逻辑地址对应的物理地址
   1. 缓存中没有则到内存中找
3. MMU向内存控制器发出某一物理地址的请求
4. 内存返回该物理地址的内容



* 物理地址
* 逻辑地址：段内偏移地址
  * 也称为有效地址
  * 即一个运行的程序所拥有的（所能看到的）内存范围。
* 线性地址：保护模式下“段基址+段内偏移地址”称为线性地址
  * 因为此时的“段基址”是段选择子，是个索引。
  * 若没有开启分页功能，索引替换后的地址就是物理地址
  * 若开启分页，线性地址也称为虚拟地址



# 连续内存分配

## 基础分配策略

经典的三种分配策略：首次适配、最优适配、最差适配

* （按地址）首次适配
  * 设需要分配大小为x，则找到第一块比x大的空闲块分配给他
  * 实现：将空闲块按地址排序，回收时检查能否与周围空闲块合并
  * 优点：简单，易于产生更大的空间块
  * 缺点：易产生外碎片，不确定性
* 最优适配
  * 设需要分配大小为x，则找到比x大但差值最小的空闲块分配给他
  * 实现：将空闲块按大小排序，回收时搜索并合并周围空闲块
  * 优点：避免大空间块被拆散，一定程度上减小了外碎片的尺寸，适合大部分分配为小尺寸时的分配
  * 缺点：重分配很慢，易产生难以利用的微小碎片
* 最差适配
  * 将最大的空闲块拆出需要的空间大小分配给程序
  * 实现：将空闲块按大小排序，回收时搜索并合并周围空闲块
  * 优点：如果分配是中等尺寸的效果最好
  * 缺点：重分配慢，外部碎片，当需求大的空闲块时难以满足



很难说哪个是所谓最好的分配策略，程序对空闲块的需求也是充满随机性的。

## 内存碎片整理

空闲内存无法被利用。

* 外碎片：分配单元之间的内存碎片
* 内碎片：分配单元中的内存碎片

### 压缩式碎片整理

最直观的方法，也就是暴力挪移，将所有的程序挪到一起。但这种方法开销很大。

### 交换式碎片整理

将没有运行的程序导出到硬盘（虚拟内存）



# 离散内存分配：分段机制

当一个程序准许运行在内存中时，操作系统要为其（和其数据）分配一个连续的区间。

> 关于保护模式和分段机制，在组原部分已经有做过比较详细的笔记。

# 精益求精：分页机制

即使是有这样那样的内存分配策略和碎片整理方案，显然分段机制依旧存在较大的性能问题。

很自然地将目光转到非连续内存管理（分页机制）。

* 更好的内存利用和管理
* 允许共享代码与数据
* 支持动态加载和动态链接

非连续内存管理的优势和诱惑力毋庸置疑，但也会有一些小缺点

* 用软件方案实现非连续内存管理会带来巨大的开销

## 分页机制概述

可以视为分段机制的增强版。

* 页（Page）/页帧（Frame）的大小是固定的。
  * 一般为4KB（或者其他2的幂次）
  * 页是逻辑概念，代表一段逻辑地址空间，帧是物理概念，代表一段物理地址空间
    * 页和帧之间一一对应
  * 在分段机制里，段的大小是可变的（但粒度往往还是偏大，导致碎片也大）。
* 划分逻辑地址空间至相同大小的页（Page）
* 建立方案将逻辑地址转换为物理地址
  * 页表
  * MMU/TLB



一个物理地址是一个二元组（帧号f，帧内偏移o），帧号有F位（F个bit），帧内偏移有S位（S个bit）。

一个逻辑地址也是一个二元组（页号p，帧内偏移o），页号有P位（P个bit），帧内偏移有S位（S个bit）。

物理地址即为$2^S \times f + o$，，同理逻辑地址为$2^S \times p + o$

> 显然，特定位数（32或64）下，切分为二元组（帧号和帧内偏移）前后的寻址空间是一样的。
>
> 分页仅仅在逻辑上把一个特定位数（如32位）的地址截成了两部分，后半部分（如果帧大小4KB则为后12bit）为帧内偏移，前半部分为页帧号。

其映射关系如下图所示

![](C:/Users/Five/Desktop/note/img/frame_page_mapping.png)



通常来说$P \geq F, p\neq f$，但页和帧的$S$是一样的，逻辑地址页内偏移和对应物理地址的帧内偏移$o$也一样。

上图中的两个页0x000和0x010**对应同一物理帧0x000**，所以两者一般**不会同时存在于物理内存**中，即对某一页的寻址可能会存在缺页。

### 寻址过程

查页表，根据页号得到对应的帧号。

一般来说，逻辑地址空间要大于物理地址空间，不是所有的页都有对应的帧，物理地址空间可以靠虚拟内存扩充。

页是连续的逻辑（虚拟）内存，帧是非连续的物理内存。



### 页表实现

除了page number之外还有标志位

* dirty bit
* resident bit
* clock/reference bit



但页表依旧存在很多问题：

* 访问一个内存单元需要2次内存访问。
* 页表所占空间可能会很大
  * 对于64位机器逻辑地址空间可达$2^{64}$字节，16EB，相应地，页表也会很大。
  * n个程序会对应n个页表





## 遇事不决上缓存：TLB

Translation Look-aside Buffer，转译后备缓冲，aka快表。

* 如果TLB命中，物理页号可以很快被获取
* 如果TLB未命中，对应的表项更新到 TLB中
  * 在编程的时候尽量具有局部性，减少TLB的缺失
  * 在x86芯片中，TLB缺失由硬件完成更新
  * 在MIPS中，由操作系统完成更新



### TLB的物理位置

TLB是一种特殊的高速缓存。

Translation Look-aside Buffer，个人感觉与其翻译为快表，不如直译成用于地址转换的高速缓存。

TLB是对页表机制的一种硬件支持。

![image-20210328165621017](C:\Users\Five\Desktop\note\img\image-20210328165621017.png)

TLB使用associative memory实现，具备快速访问性能

* 关联存储器可以被认为是一种存储单元, 其存储的数据可以通过数据本身的内容而不是通过地址或存储位置来标识以便访问。

> 这一块感觉稍微有些8太通，Intel Skylake Microarchitecture给出的数据是8 ways associativity，不是全相联啊，俺不打算深究，反正就当一块专门用于缓存页表的SRAM理解就是了，管他是不是CAM（Content Address Memory）呢。

> 最好的情况下，虚拟地址由TLB进行转换，然后被送到cache，找到相应的数据，取回并送入处理器——访问两次高速缓存。
>
> 最坏的情况下，访问在TLB、页表、cache三个部件中都缺失——要访问两次内存、一次硬盘。



> TLB可以介于CPU和高速缓存（SRAM）之间，也可以介于高速缓存和主存（DRAM）之间，取决于缓存使用的是物理寻址还是虚拟寻址。

## 更多

### 多级页表

一级页表存储二级页表的起始地址，二级页表存储真正的帧号frame number。



* 若一级页表p1中某个页表项不存在（驻留位为0），对应的二级页表整个Page Table都不需要放在内存中





当然，多级页表可以节省空间，其代价就是每次寻址都需要更多次地访问内存：天下没有免费的午餐。



### 反向页表

逻辑地址空间（从32bit到64-bit）增长速度远快于物理地址空间。

但是反向页表如何通过页号查找对应的帧号呢？

* 关联存储器
  * 硬件限制，不可能做得很大。
  * 关联存储器是放在CPU的，否则依旧会有内存访问问题
* 基于哈希的方案
  * 可以用硬件加速哈希运算
  * 会有哈希冲突



## 漫漫的寻址路



![](C:/Users/Five/Desktop/note/img/the_adventure_of_an_address.svg)

# 更大的空间和虚拟内存

> SRAM是DRAM的Cache。
>
> 同理，把视角拉大，把磁盘看作主角，那虚拟内存技术不就是将DRAM视为磁盘的Cache吗。

> 已经设计出这样的系统：对程序员来说，复合的存储结构看起来像单层的存储器，所需的数据传输也会自动完成。
>
> ——《One-level Storage System》Kilburn等

## Overlay

操作系统还远没有今天完善的年代，一切需求都由写程序的程序员自己完成。

在较小的可用内存中运行较大的程序，常用于多道程序系统，与分区存储管理配合使用。



程序按照自身的逻辑结果，切分为若干个功能上相互独立的模块，不会（或者说不需要）同时运行的模块共享同一块内存区域——谁来了谁执行，另一个退出到磁盘。

![image-20210310145330611](C:\Users\Five\Desktop\note\img\image-20210310145330611.png)

通过调整覆盖、共用方式，还可以进一步减小所需内存：B、E、F没有调用关系，共用一个50K覆盖区，C、D没有调用关系，共用一个30K覆盖区，如此一来内存比上图又少用了10KB。

而这一切，都需要程序员自己进行精心的考量和设计。

> 换入换出需要大量的实践，所以可以说，还是一种以时间换空间的行为。

## Swapping

* 操作系统把一个暂时不能运行的进程的整个地址空间的内容保存到外存中。
* 换入换出的粒度为整个程序的地址空间。





* 换出再换入后地址可能会不一样

> 覆盖（Overlay）更多的是在一个程序内的内存控制，由程序设计者自己完成，交换（Swapping）是不同程序间的内存共享控制，由操作系统完成。

## 虚拟内存技术

覆盖技术对于程序员的负担较大，交换技术换入换出的粒度太大，导致开销很大。

虚拟内存技术的目标就是结合两者的优势，消除两者的不足。



* 程序的局部性原则（Principle of locality）
  * 程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址分别局限于一定区域内。
  * 这是为虚拟内存能有效运行而对程序员提出的开发要求

经典的外循环和内循环差异：

```c++
for(j = 0; j < 1024; j++)
    for(i = 0; i < 1024; i++)
        A[i][j]=0
```

```c++
for(i = 0; i < 1024; i++)
    for(j = 0; j < 1024; j++)
        A[i][j]=0
```

由于C语言的数组存储行优先（也有不少列优先的语言），前者代码会有更多缺页中断，效率会大幅降低。

如果没有局部性，操作系统会很难推测那些代码/数据该被放入更高级的存储层次中。



有了局部性的保证之后，虚拟内存技术便可以基于页式或段式内存管理实现，并得到很好的效果。

### 请求调页

当一个用户程序调入内存运行时，不是将该程序的所有页面都装入内存，而是只装入部分的页面，就可启动程序运行。

当发现要运行或访问的数据不在内存时向系统发出缺页中断请求。

![](C:/Users/Five/Desktop/note/img/1518162-20190114140729006-1391783543.png)

简单来说有

* 驻留位：表明该页是否在内存中，为0表示在外存中
* 保护位：对权限进行检查
* 修改位：是否被修改，系统回收当前内存时通过该位决定是否需要更新外存
  * 若未被修改过，直接free当前内存即可，下次再需要就再从外存调
* 访问位：访问频率决定这个页配不配继续留在内存里。

![image-20210310155959206](C:\Users\Five\Desktop\note\img\image-20210310155959206.png)

### 缺页中断

1. 如果内存中有空闲的物理内存页面，则分配之，并跳转到第4步
2. 采用某种页面置换算法，选择一个用于替换的物理页帧
   1. 若该页帧被修改过，需要更新外存
3. 修改原虚拟页表项驻留位为0
4. 将对应页装入物理内存页面
5. 修改被载入的虚拟页表驻留位为1，并修改物理页帧号指向该物理页帧
6. 中断处理完成，继续执行指令



## 页面置换算法





## 对比Cache和虚拟内存

在Cache以数据块为单位和DRAM进行数据交换——虚拟存储器同样如此，以页为单位和磁盘进行数据交换。

在Cache中未命中存在访问缺失——虚拟存储器同样如此，会有缺页




## 历史的车轮[^1]

构造虚拟存储器主要有两个动机：

* 允许云计算在多个虚拟机之间有效而安全地共享存储器
* 消除一个小而受限的主存容量对程序设计造成的影响

50年后的今天，第一条变成了主要设计动机。

# 简史和总结

前面洋洋洒洒写了很多，但内容很松散，也很难把握主线，所以想换个角度再叙述一次内存管理的发展。

希望能更好地描绘出存储管理发展背后的脉络。



## 实模式

直接通过段基址（段寄存器<<4）+段内偏移（指针寄存器或立即数）的方式访问物理地址。

简洁明了，没有那么多花里胡哨，20根地址线，最大寻址空间1MB。

此时采用的分段机制，最主要的目的（也可能单纯就只有这一个目的）是希望获得更大的寻址空间，即能用16位寄存器访问1MB的地址空间。

## 保护模式和分段机制的蜕变

在IA-32中引入了保护模式。

> 关于保护模式和段描述符表的具体内容就不在此赘述了，此处重在理清脉络。可参见组成原理部分的笔记。

分段机制还是叫分段机制，但已经不是无论是需求还是具体实现，都已经完完全全不是原来的分段机制了。（大概可以理解为卡卡罗特变身超级赛亚人前后？）

需求方面：

* 有些需求保持：程序可以（事实上也确实应该）对自己的物理地址一无所知，而只关注自己的逻辑地址。
* 有些需求废弃：32位的的寄存器有4G的寻址空间，更不用说64位的寄存器，显然不需要靠分段获得更大的寻址空间。
* 有些需求新增：权限保护，不能任意一个程序都能随随便便访问整个内存空间，干扰甚至恶意阻碍其他程序的执行。

实现方面：

* 直接拉出一块内存，放一个表，将程序的逻辑地址空间和物理地址空间对应起来

这种分段基址的实现也带来了一个问题：**一次寻址要访问两次内存**——先查表得到对应物理地址，再访问具体的物理地址。

遇事不决上缓存——快表。



## 分页机制

分页，是又一次进化——就像从牛顿力学到相对论一样。

分页在一定程度上优化了内存碎片的利用问题（分段的粒度太大，小碎片不好利用），但这仅仅是冰山一角。

从Swapping技术到虚拟内存技术的背后，也离不开分页技术对分段技术的取代。









![image-20220111115028755](C:\Users\Five\Desktop\note\img\image-20220111115028755.png)

[^1]:《计算机组成与设计：软件/硬件接口》